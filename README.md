Bias in NLP
=======


This is a collection of natural language processing papers that deal with bias (mostly gender bias). The list is by no means complete and is just a way to keep up with the large amount of papers in that area. If you miss a paper, please add it. 


TODOS
* add papers from [GeBNLP2020](https://genderbiasnlp.talp.cat/gebnlp2020/accepted-papers/) once they are available.

Papers
-----



**Towards Detection of Subjective Bias using Contextualized Word Embeddings**  
WebConf2020 - [Paper](https://arxiv.org/pdf/2002.06644.pdf), [Code](https://github.com/tanvidadu/Subjective-Bias-Detection)  
*Note:* Wikineutrality Corpus.


**Joint Multiclass Debiasing of Word Embeddings**  
ISMIS2020 - [Paper](https://arxiv.org/pdf/2003.11520.pdf), [Code](https://github.com/RadomirPopovicFON/Joint-Multiclass-Debiasing-of-Word-Embeddings)  
*Note:* Hard and Soft WEAT


**Towards Debiasing Sentence Representations**  
ACL2020 - [Paper](https://pdfs.semanticscholar.org/0d96/5ed237a3b4592ecefdb618c29f63adedff76.pdf), [Code](https://github.com/pliang279/sent_debias)  
*Note:* Sentence-level debiasing. Difference between pretraining and finetuning. 


**Neutralizing Gender Bias in Word Embedding with Latent Disentanglement and Counterfactual Generation**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2004.03133.pdf)  
*Note:* Counterfactual generation.


**Unsupervised Discovery of Implicit Gender Bias**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2004.08361.pdf), [Code](https://github.com/anjalief/unsupervised_gender_bias)  
*Note:* Unsupervised bias detection from comments. 


**StereoSet: Measuring stereotypical bias in pretrained language models**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2004.09456.pdf), [Code](https://stereoset.mit.edu/)  
*Note:* Benchmark and Dataset for measuring bias in 4 domains (gender, profession, race, religion).


**Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation**  
ACL2020 - [Paper](https://arxiv.org/pdf/2005.00965.pdf), [Code](https://github.com/uvavision/Double-Hard-Debias)  
*Note:* Double Hard Debias: mitigigate dataset and then do debiasing


**Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer**  
ACL2020 - [Paper](https://arxiv.org/pdf/2005.00699.pdf)  
*Note:* Bias in multilingual embeddings depends on the alignment direction.


**Scalable Cross Lingual Pivots to Model Pronoun Gender for Translation**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2006.08881.pdf)  
*Note:* Gender labels for pronouns in MT English-Spanish.


**Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2006.03955.pdf)  
*Note:* CEAT


**OSCaR: Orthogonal Subspace Correction and Rectification of Biases in Word Embeddings**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2007.00049.pdf)  
*Note:* Preserve semantic meaning of embeddings. 


**Investigating Gender Bias in BERT**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2009.05021.pdf)  
*Note:* Identify one gender direction per BERT layer.


**Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2009.11982.pdf), [Code](https://github.com/anavaleriagonzalez/ABC-dataset)  
*Note:* Multilingual multitask dataset across 4 languages.


**Towards Debiasing NLU Models from Unknown Biases**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2009.12303.pdf), [Code](https://github.com/UKPLab/emnlp2020-debiasing-unknown)  
*Note:* Unsupervised bias detection.


**Robustness and Reliability of Gender Bias Assessment in Word Embeddings: The Role of Base Pairs**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2010.02847.pdf), [Code](https://github.com/alisonsneyd/Gender_bias_word_embeddings)  
*Note:* Choice of base pairs is relevant.


**LOGAN: Local Group Bias Detection by Clustering**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2010.02867.pdf)  
*Note:* Identify biases through clustering.


**Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2009.09435.pdf)  
*Note:* Verify whether non-linear debiasing helps. It seems not.


**Unmasking Contextual Stereotypes: Measuring and Mitigating BERT’s Gender Bias**  
GeBNLP2020 - [Paper](https://arxiv.org/pdf/2010.14534.pdf), [Code](https://github.com/marionbartl/gender-bias-BERT)  
*Note:* Verify gender debiasing techniques in German.


**Language (Technology) is Power: A Critical Survey of “Bias” in NLP**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2005.14050.pdf)  
*Note:* Metastudy: survey of 146 gender bias papers


**Pick a Fight or Bite your Tongue: Investigation of Gender Differences in Idiomatic Language Usage**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2011.00335.pdf)  
*Note:* Idiomatic expressions depending on the speaker.


**Evaluating Bias In Dutch Word Embeddings**  
GeBNLP2020 - [Paper](https://arxiv.org/pdf/2011.00244.pdf), [Code](https://github.com/Noixas/Official-Evaluating-Bias-In-Dutch)  
*Note:* Examining bias in Dutch (using WEAT)


**Analyzing Gender Bias within Narrative Tropes**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2011.00092.pdf), [Code](https://github.com/dhruvilgala/tvtropes)  
*Note:* Analyze bias using tropes


**Neural Machine Translation Doesn’t Translate Gender Coreference Right Unless You Make It**  
GeBNLP2020 - [Paper](https://arxiv.org/pdf/2010.05332.pdf), [Code](https://github.com/DCSaunders/tagged-gender-coref)  
*Note:* Incorporate explicit word-level gender tags.


**The Gap on GAP: Tackling the Problem of Differing Data Distributions in Bias-Measuring Datasets**  
NeurIPS 2020 - [Paper](https://arxiv.org/pdf/2011.01837.pdf), [Code](https://github.com/vid-koci/weightingGAP)  
*Note:* Distances in GAP play a role.


**AraWEAT: Multidimensional Analysis of Biases in Arabic Word Embeddings**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2011.01575.pdf), [Code](https://github.com/bakrianoo/aravec)  
*Note:* Arabic WEAT.


**Characterising Bias in Compressed Models**  
arxiv2020 - [Paper](https://arxiv.org/pdf/2010.03058.pdf)  
*Note:* Bias in compressed model is large. Provide method to identify biased examples.


**Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them**  
NAACL2019 - [Paper](https://arxiv.org/pdf/1903.03862.pdf), [Code](https://github.com/gonenhila/gender_bias_lipstick)  
*Note:* Debiasing by setting dimensions to zero ist not effective


**Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques**  
GeBNLP 2019 - [Paper](https://arxiv.org/pdf/1901.03116.pdf)  
*Note:* Spanisch-Englisch translation with occupations.


**Evaluating the Underlying Gender Bias in Contextualized Word Embeddings**  
GeBNLP 2019 - [Paper](https://arxiv.org/pdf/1904.08783.pdf)  
*Note:* Cointextualized embeddings are less biased than static ones. 


**Mitigating Gender Bias in Natural Language Processing: Literature Review**  
ACL2019 - [Paper](https://www.aclweb.org/anthology/P19-1159.pdf)  
*Note:* Survey


**What's in a Name? Reducing Bias in Bios without Access to Protected Attributes**  
NAACL2019 - [Paper](https://arxiv.org/abs/1904.05233)  
*Note:* Work on biographies. 


**Assessing Social and Intersectional Biases in Contextualized Word Representations**  
NeurIPS2019 - [Paper](https://papers.nips.cc/paper/9479-assessing-social-and-intersectional-biases-in-contextualized-word-representations.pdf)  
*Note:* Strong bias in contextualized embeddings. Bias not always visible on sentence level. 


**It’s All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution**  
EMNLP2019 - [Paper](https://arxiv.org/pdf/1909.00871.pdf)  
*Note:* Counterfactual Data Substitution (CDS)


**Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis**  
GeBNLP 2019 - [Paper](https://arxiv.org/pdf/1906.10256.pdf), [Code](https://github.com/jayadevbhaskaran/gendered-sentiment)  
*Note:* Dataset of 800 sentences analysed with sentiment analysis.


**Automatic Gender Identification and Reinflection in Arabic**  
GeBNLP 2019 - [Paper](https://www.aclweb.org/anthology/W19-3822)  
*Note:* Arabic English Translation with focus on getting the pronouns right.


**Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling**  
GeBNLP 2019 - [Paper](https://www.aclweb.org/anthology/W19-3820.pdf), [Code](https://github.com/sattree/gap)  
*Note:* Shared task winner GAP


**Gendered Ambiguous Pronouns (GAP) Shared Task at the Gender Bias in NLP Workshop 2019**  
GeBNLP 2019 - [Paper](https://www.aclweb.org/anthology/W19-3801/), [Code](https://github.com/google-research-datasets/gap-coreference)  
*Note:* GAP shared task description


**Conceptor Debiasing of Word Representations Evaluated on WEAT**  
GeBNLP 2019 - [Paper](https://arxiv.org/pdf/1906.05993.pdf)  
*Note:* Proposes Conceptor Debiasing.


**On Measuring Gender Bias in Translation of Gender-neutral Pronouns**  
GeBNLP 2019 - [Paper](https://arxiv.org/pdf/1905.11684.pdf), [Code](https://github.com/nolongerprejudice/tgbi)  
*Note:* Gender bias in pronoun translation Korean-English


**Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories**  
GeBNLP 2019 - [Paper](https://www.aclweb.org/anthology/W19-3804), [Code](https://github.com/alfredomg/GeBNLP2019)  
*Note:* Clustering method for discovering new biases. 


**The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations**  
GeBNLP 2019 - [Paper](https://www.aclweb.org/anthology/W19-3808)  
*Note:* Uses conceptor debiasing


**The Woman Worked as a Babysitter: On Biases in Language Generation**  
EMNLP2019 - [Paper](https://arxiv.org/pdf/1909.01326.pdf), [Code](https://github.com/ewsheng/nlg-bias)  
*Note:* Regard and Sentiment. Annotations released. 


**Exploring Human Gender Stereotypes with Word Association Test**  
EMNLP2019 - [Paper](https://www.aclweb.org/anthology/D19-1635.pdf), [Code](https://github.com/Yupei-Du/bias-in-wat)  
*Note:* Word association graphs


**Gender-preserving Debiasing for Pre-trained Word Embeddings**  
ACL2019 - [Paper](https://arxiv.org/pdf/1906.00742.pdf), [Code](https://github.com/kanekomasahiro/gp_debias)  
*Note:* Differentiate between bias and gender information. 


**Quantifying Social Biases in Contextual Word Representations**  
GeBNLP 2019 - [Paper](https://www.cs.cmu.edu/~ytsvetko/papers/bias_in_bert.pdf)  
*Note:* Template based method to quantify bias.


**Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting**  
ACM Fat 2019 - [Paper](https://arxiv.org/pdf/1901.09451.pdf)  
*Note:* Analyze effects of bias.


**Gender Bias in Neural Natural Language Processing**  
Logic, Language, and Security. Springer. 2018 - [Paper](https://arxiv.org/pdf/1807.11714.pdf)  
*Note:* Counterfactual Data Augmentation (CDA). Clear definition of Bias. Evaluates on coreference resolution and language modelling.


**Gender Bias in Coreference Resolution**  
NAACL2018 - [Paper](https://arxiv.org/pdf/1804.09301.pdf), [Code](https://github.com/rudinger/winogender-schemas)  
*Note:* Windogender schemes.


**Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings**  
NeurIPS2016 - [Paper](http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf), [Code](https://github.com/tolga-b/debiaswe)  
*Note:* Among the first to address gender bias


**Rejecting the Gender Binary: A Vector-Space Operation.**  
2015 - [Paper](http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html)  
*Note:* Blog post: first to propose to remove gender dimension
